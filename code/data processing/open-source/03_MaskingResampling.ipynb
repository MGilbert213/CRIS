{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask and resample\n",
    "\n",
    "This is the third notebook in a series of six notebooks designed to run sequentially. \\\n",
    "Run this notebook to apply a mask for the Contiguous United States (CONUS) to the STAR and LOCA2 data and to resample the STAR data to the LOCA2 grid. \\\n",
    "Download the mask from https://github.com/NOAA-CRIS/CRIS/tree/main/data/TSU_land_only_mask_LOCA2grid_STARwaterbodies.tif to <your-base-path>/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import logging\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from osgeo import gdal\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "    \"\"\"\n",
    "    Checks if directory exists and if not it will create it\n",
    "    \n",
    "    dir: str\n",
    "        full path the directory\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir):\n",
    "            os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir_return_list_by_selection(workspace, ssp, model):\n",
    "    \"\"\"\n",
    "    Lists all files in a workspace and return the full path\n",
    "\n",
    "    workspace: str\n",
    "        full path the directory\n",
    "    selection: str\n",
    "        string used as a filter \n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(workspace):\n",
    "        if ssp in file and model in file:\n",
    "            files.append(os.path.join(workspace,file))\n",
    "    return(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_to_target_rasters(source_grid, target_grid):\n",
    "\n",
    "    source_x = source_grid.longitude.values\n",
    "    source_y = np.flipud(source_grid.latitude.values)\n",
    "    source_xx, source_yy = np.meshgrid(source_x, source_y)\n",
    "    source_points = np.vstack((source_xx.ravel(), source_yy.ravel())).T\n",
    "\n",
    "    target_x = target_grid.lon.values\n",
    "    target_y = np.flipud(target_grid.lat.values)\n",
    "    target_xx, target_yy = np.meshgrid(target_x, target_y)\n",
    "\n",
    "    return source_points, target_xx, target_yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Logger and Open Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your base directory\n",
    "base = r'C:\\<your-base-path>\\CRIS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE_PATH = os.path.join(base, 'logs')\n",
    "\n",
    "# Setup logging to file and stdout\n",
    "file_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "log_file_name = \"Output_Log_ResamplingMasking_\" + file_time + \".log\"\n",
    "LOG_FILE = os.path.join(LOG_FILE_PATH, log_file_name)\n",
    "\n",
    "logging.basicConfig(level = logging.INFO,\n",
    "                    format=\"%(asctime)s:%(levelname)s: %(message)s\",\n",
    "                    handlers=[\n",
    "                       logging.FileHandler(filename=LOG_FILE),\n",
    "                       logging.StreamHandler()\n",
    "                   ])\n",
    "logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(base, 'data', 'unitconvert')\n",
    "output_dir = os.path.join(base, 'data', 'resample_mask')\n",
    "\n",
    "create_dir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of the source grid (STAR). it does not matter what the actual model and variable in the file are.\n",
    "source_grid = xr.open_dataset(os.path.join(base, 'data', 'merge', 'STAR', 'cdd', 'STAR_ACCESS-CM2_cdd_ssp245_1950_2100.nc'))\n",
    "\n",
    "# example of the correct LOCA2 grid (target). it does not matter what the actual model and variable in the file are.\n",
    "target_grid = xr.open_dataset(os.path.join(base, 'data', 'merge', 'LOCA2', 'cdd', 'LOCA2_ACCESS-CM2_cdd_ssp245_1950_2100.nc'))\n",
    "\n",
    "# create raster conversion\n",
    "source_points, target_xx, target_yy = source_to_target_rasters(source_grid, target_grid)\n",
    "\n",
    "# load mask\n",
    "# Download the mask from https://github.com/NOAA-CRIS/CRIS/tree/main/data/TSU_land_only_mask_LOCA2grid_STARwaterbodies.tif to <your-base-path>/data\n",
    "mask_path = os.path.join(base, 'data', 'TSU_land_only_mask_LOCA2grid_STARwaterbodies.tif')\n",
    "mask = gdal.Open(mask_path)\n",
    "mask = mask.GetRasterBand(1).ReadAsArray()\n",
    "mask = np.flipud(np.where(mask == 3, np.nan, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick STAR or LOCA2\n",
    "model_set = 'LOCA2'\n",
    "\n",
    "# pick model\n",
    "model = 'ACCESS-CM2'\n",
    "\n",
    "# pick variable\n",
    "variable = 'tavg'\n",
    "\n",
    "ssp_list = ['_ssp245','_ssp370','_ssp585']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_proc_tm = time.time() \n",
    "\n",
    "# Define a local directory\n",
    "netcdf_dir_list = os.path.join(input_dir, model_set, variable)\n",
    "\n",
    "# Define the full directory path\n",
    "output_dir_model_set = os.path.join(output_dir, model_set)\n",
    "\n",
    "# Create an output folder for the model set\n",
    "create_dir(output_dir_model_set)\n",
    "logging.info(f\"Created [{output_dir_model_set}] for processing\")\n",
    "\n",
    "# Define the full directory path\n",
    "output_dir_model_set_variable = os.path.join(output_dir_model_set, variable)\n",
    "\n",
    "# Create an output folder for the model variable\n",
    "create_dir(output_dir_model_set_variable)\n",
    "logging.info(f\"Created [{output_dir_model_set_variable}] for processing\")\n",
    "\n",
    "# Execute the workflow by ssp in a for loop\n",
    "for ssp in ssp_list:\n",
    "\n",
    "    ssp_rasters = list_dir_return_list_by_selection(netcdf_dir_list, ssp, model)\n",
    "\n",
    "    # Strip .xmls from the ssp_rasters list\n",
    "    ssp_rasters = list(set([str(item).strip(\".xml\") for item in ssp_rasters]))\n",
    "    total_recs = len(ssp_rasters)\n",
    "    logging.info(f\"There are [{total_recs}] files in SSP[{ssp.strip('_ssp')}]\")\n",
    "    rec_count = 0\n",
    "\n",
    "    start_rec_tm = time.time()\n",
    "    \n",
    "    for netcdf in ssp_rasters:\n",
    "\n",
    "        rec_count += 1\n",
    "        start_rec_tm = time.time()\n",
    "\n",
    "        # Split the file name by underscore and collect the parts for processing\n",
    "        file_name_parts = os.path.basename(ssp_rasters[0]).strip('.nc').split(\"_\")\n",
    "\n",
    "        # path to save output to\n",
    "        out_raster_path = os.path.join(output_dir, model_set, variable, os.path.basename(netcdf))\n",
    "\n",
    "        # Collect file names parts\n",
    "        model_set, model, variable, ssp, start_year, end_year = file_name_parts\n",
    "        logging.info(f\"Processing {os.path.join(netcdf_dir_list, '_'.join([model,variable,ssp]))}\")\n",
    "                \n",
    "        if model_set == 'STAR':\n",
    "            \n",
    "            # create a temporary raster\n",
    "            temp_raster = np.zeros((target_grid['cdd'].shape))\n",
    "\n",
    "            # open netcdf\n",
    "            raster_proc = xr.open_dataset(netcdf)\n",
    "\n",
    "            # loop through time dimension (151 steps)\n",
    "            for t in range(raster_proc[variable.replace('-','_')].shape[0]):\n",
    "                \n",
    "                print('Processing:', t+1950)\n",
    "\n",
    "                # convert raster values to 1D array\n",
    "                source_values = np.flipud(raster_proc[variable.replace('-','_')][t,:,:].values)\n",
    "                \n",
    "                source_values_flat = source_values.ravel()\n",
    "\n",
    "                # resample data\n",
    "                temp_raster[t,:,:] = griddata(source_points, source_values_flat, (target_xx, target_yy), method='linear')\n",
    "            \n",
    "            # Clip temp_raster with mask\n",
    "            out_raster = temp_raster * mask\n",
    "\n",
    "            end_red_tm = time.time()\n",
    "            elapsed_rec_tm = end_red_tm - start_rec_tm\n",
    "            logging.info(f\"[Processed: {os.path.join(netcdf_dir_list, ':', ssp)} in {elapsed_rec_tm:0,.2f} seconds]\")\n",
    "\n",
    "        elif model_set == 'LOCA2':\n",
    "\n",
    "            # open netcdf\n",
    "            raster_proc = xr.open_dataset(netcdf)\n",
    "\n",
    "            # Clip raster with mask\n",
    "            raster_proc = raster_proc.isel(lat=slice(None, None, -1))\n",
    "            out_raster = raster_proc[variable.replace('-','_')].values * mask\n",
    "\n",
    "            end_red_tm = time.time()\n",
    "            elapsed_rec_tm = end_red_tm - start_rec_tm\n",
    "            logging.info(f\"[Processed: {os.path.join(netcdf_dir_list, ':', ssp)} in {elapsed_rec_tm:0,.2f} seconds]\")\n",
    "\n",
    "        # create an independent copy of target_grid and repopulate it with the newly calculated out_raster\n",
    "        final_grid = deepcopy(target_grid).rename({'cdd': variable.replace('-','_')})\n",
    "        final_grid[variable.replace('-','_')][:,:,:] = np.flip(out_raster, axis=1)\n",
    "        \n",
    "        # save the regridded and masked data as netcdf\n",
    "        final_grid.to_netcdf(out_raster_path, encoding={variable.replace('-','_'): {'zlib': True, 'complevel': 9}})\n",
    "\n",
    "logging.info(\"Processing complete.\")\n",
    "end_proc_tm = time.time()\n",
    "\n",
    "elapsed_proc_tm = end_proc_tm - start_proc_tm\n",
    "\n",
    "logging.info(f\"[Overall Elapsed time: {elapsed_proc_tm/60:0,.2f} minutes]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3-raf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
